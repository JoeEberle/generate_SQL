{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "237aab5c",
   "metadata": {},
   "source": [
    "# Generate SQL\n",
    "\n",
    "#### Generates SQL for table creation, sample queries and ETL Processing \n",
    "\n",
    "The quote from Good Will Hunting (1997) is:\n",
    "\n",
    "***\"My boy's wicked smart.\"*** â€“ Morgan O'Mally (played by Casey Affleck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b660f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_intallation = False \n",
    "if first_intallation: \n",
    "    !pip install --upgrade bottleneck\n",
    "    !pip install pipreqs\n",
    "# pipreqs /path/to/your/project --force    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "deffe246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Imported succesfully on 2025-04-08 at 19:05:26.037357\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import schedule\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numbers\n",
    "import file_manager as fm \n",
    "import quick_logger as ql \n",
    "import talking_code as tc \n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "from IPython.display import Video\n",
    "import time\n",
    "import story_board as sb \n",
    "import postgres_utils as pg\n",
    "from IPython.display import Markdown, display, Image\n",
    "print(f\"Libraries Imported succesfully on {datetime.now().date()} at {datetime.now().time()}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7f1918-fc06-4335-81bc-17557136ddcd",
   "metadata": {},
   "source": [
    "#### Required Setup Step 0 - Intitiate Configuration Settings and name the overall solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1984f04-117f-4dc5-98e9-9c701b3e3a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser \n",
    "config = configparser.ConfigParser()\n",
    "cfg = config.read('config.ini')  \n",
    "solution_name = 'sql_generation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092cdb4f-95e5-4d0b-9435-f60b3f117f8b",
   "metadata": {},
   "source": [
    "#### Required Setup Step 0 - Intitiate Logging and debugging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3697cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process started sql_generation on Date:04-08-2025 at Time:06:59:55 PM \n"
     ]
    }
   ],
   "source": [
    "import logging # built in python library that does not need to be installed \n",
    "import file_manager as fm \n",
    "import quick_logger as ql \n",
    "\n",
    "global start_stime \n",
    "start_time = ql.set_start_time()\n",
    "logging = ql.create_logger_start(solution_name, start_time) \n",
    "ql.pvlog('info',f\"Process started {solution_name} on Date:{datetime.now().strftime('%m-%d-%Y')} at Time:{datetime.now().strftime('%I:%M:%S %p')} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8934b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<docx.text.paragraph.Paragraph at 0x1fc837c4d70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new Document\n",
    "report_date_stamp = datetime.now().date()\n",
    "report_time_stamp = datetime.now().time()\n",
    "data_story_doc = Document()\n",
    "data_story_doc.add_heading(f\"Data Science Story Board - {solution_name}\", level=1)\n",
    "data_story_doc.add_heading(f\"Processed on : {report_date_stamp} at {report_time_stamp}\", level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456454de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91b853b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0abe3d82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "## Generate SQL\n",
       "\n",
       "1. **Create Table**  \n",
       "2. **SQL Select**  \n",
       "3. **ETL Process**  \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "definition = '''\n",
    "\n",
    "## Generate SQL\n",
    "\n",
    "1. **Create Table**  \n",
    "2. **SQL Select**  \n",
    "3. **ETL Process**  \n",
    "\n",
    "''' \n",
    "# Write the solution definitions out to the solution_description.md file\n",
    "file_name = \"generate_sql.md\"\n",
    "with open(file_name, 'w', encoding='utf-8') as f:\n",
    "    f.write(definition)  # Write the template to the readme.md file\n",
    "\n",
    "# Display the definition as formatted Markdown in the notebook\n",
    "display(Markdown(definition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a1ba0dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## Generate SQL\n",
       "\n",
       "ðŸ”¹ Generate SQL will generate various forms of SQL based upon the datas descriptive statistics\n",
       "\n",
       "1. âœ… **Create Table** â†’ Adds a **table_name** for the table or dataset.\n",
       "2. âœ… **SQL Select** â†’ Adds a **column_name** for current column, how pandas named the raw data.\n",
       "3. âœ… **ETL Process** â†’ Adds a column for the **pandas.dtype**, how pandas inferred the raw data.\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "definition = '''\n",
    "## Generate SQL\n",
    "\n",
    "ðŸ”¹ Generate SQL will generate various forms of SQL based upon the datas descriptive statistics:\n",
    "\n",
    "1. âœ… **Create Table** â†’ Adds a **table_name** for the table or dataset.\n",
    "2. âœ… **SQL Select** â†’ Adds a **column_name** for current column, how pandas named the raw data.\n",
    "3. âœ… **ETL Process** â†’ Adds a column for the **pandas.dtype**, how pandas inferred the raw data.\n",
    "\n",
    "\n",
    "''' \n",
    "sb.outmd(definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9323ab22-2334-4f3d-8507-f66533aebb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contains 1309 rows and 21 columns of titanic data\n",
      "The data contains 344 rows and 18 columns of penguins data\n",
      "The data contains 918 rows and 12 columns of heart data\n",
      "The data contains 768 rows and 9 columns of diabetes data\n",
      "The data contains 55500 rows and 15 columns of health care data\n",
      "The data contains 311745 rows and 34 columns of chronic disease data\n",
      "The data contains 1000 rows and 26 columns of HealtheLink data\n"
     ]
    }
   ],
   "source": [
    "getting_titanic_data = True\n",
    "if getting_titanic_data: \n",
    "    df = pd.read_csv(\"C:\\\\Users\\\\josep\\\\ideal_ai_data_exploration\\\\titanic.csv\")    # Read the CSV file into a pandas DataFrame\n",
    "    # df = pd.read_csv(\"https://raw.githubusercontent.com/JoeEberle/reference_datasets/main/titanic.csv\")\n",
    "    df.columns = df.columns.str.replace(' ', '_').str.lower()\n",
    "    print(f'The data contains {df.shape[0]} rows and {df.shape[1]} columns of titanic data' )\n",
    "    df_titanic = df  \n",
    "    df_titanic[\"pclass\"] = df_titanic[\"pclass\"].fillna(\"Unknown pclass\")\n",
    "    df_titanic[\"cabin\"] = df_titanic[\"cabin\"].fillna(\"Unknown cabin\")\n",
    "    df_titanic[\"sex\"] = df_titanic[\"sex\"].fillna(\"Unknown sex\") \n",
    " \n",
    "getting_penguins_data = True\n",
    "if getting_penguins_data: \n",
    "    df = pd.read_csv(\"C:\\\\Users\\\\josep\\\\DB_Discovery\\\\penguins.csv\")    # Read the CSV file into a pandas DataFrame\n",
    "    print(f'The data contains {df.shape[0]} rows and {df.shape[1]} columns of penguins data')\n",
    "    df_penguins = df       \n",
    "    \n",
    "getting_heart_data = True\n",
    "if getting_heart_data: \n",
    "    df = pd.read_csv(\"C:\\\\Users\\\\josep\\\\DB_Discovery\\\\heart.csv\")    # Read the CSV file into a pandas DataFrame\n",
    "    df.columns = df.columns.str.replace(' ', '_').str.lower()\n",
    "    print(f'The data contains {df.shape[0]} rows and {df.shape[1]} columns of heart data')\n",
    "    df_heart = df    \n",
    "    df_heart[\"patient_id\"] = df_heart.index\n",
    "\n",
    "getting_diabetes_data = True\n",
    "if getting_diabetes_data: \n",
    "    df = pd.read_csv(\"C:\\\\Users\\\\josep\\\\ideal_ai_data_exploration\\\\diabetes.csv\")    # Read the CSV file into a pandas DataFrame\n",
    "    df.columns = df.columns.str.replace(' ', '_').str.lower()\n",
    "    print(f'The data contains {df.shape[0]} rows and {df.shape[1]} columns of diabetes data')\n",
    "    df_diabetes = df \n",
    "    df_diabetes[\"patient_id\"] = df_diabetes.index\n",
    "    \n",
    "    \n",
    "getting_healthcare_data = True\n",
    "if getting_healthcare_data: \n",
    "    df = pd.read_csv(\"C:\\\\Users\\\\josep\\\\DB_Discovery\\\\healthcare_dataset.csv\")    # Read the CSV file into a pandas DataFrame\n",
    "    df.columns = df.columns.str.replace(' ', '_')\n",
    "    print(f'The data contains {df.shape[0]} rows and {df.shape[1]} columns of health care data')\n",
    "    df_healthcare = df       \n",
    "\n",
    "getting_chronic_disease_data = True\n",
    "if getting_chronic_disease_data: \n",
    "    df = pd.read_csv(\"C:\\\\Users\\\\josep\\\\DB_Discovery\\\\chronic_disease_indicators.csv\")    # Read the CSV file into a pandas DataFrame\n",
    "    df.columns = df.columns.str.replace(' ', '_')\n",
    "    print(f'The data contains {df.shape[0]} rows and {df.shape[1]} columns of chronic disease data')\n",
    "    df_chronic_disease = df        \n",
    "\n",
    "\n",
    "getting_hel_data = True\n",
    "if getting_hel_data: \n",
    "    df_hel = pd.read_excel(\"C:\\\\Users\\\\josep\\\\DB_Discovery\\\\HeWNY Sample File.xlsx\")    # Read the CSV file into a pandas DataFrame\n",
    "    df.columns = df.columns.str.replace(' ', '_')  \n",
    "    print(f'The data contains {df_hel.shape[0]} rows and {df_hel.shape[1]} columns of HealtheLink data')\n",
    "    df   = df_hel\n",
    "    df_hel = df_hel.rename(columns={'BCS': 'Breast_Cancer_Screening'})\n",
    "    df_hel = df_hel.rename(columns={'CCS': 'Cervical_Cancer_Screening'})\n",
    "    df_hel = df_hel.rename(columns={'COL': 'Colorectal_Cancer_Screening'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5ef65b4-aacd-40f5-a9a0-466f43749494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Connection to PostgreSQL successful!\n"
     ]
    }
   ],
   "source": [
    "import postgres_utils as pg\n",
    "pg_credentials = pg.get_connection_credentials()\n",
    "DB_NAME = pg_credentials[0]\n",
    "USER = pg_credentials[1]\n",
    "PASSWORD = pg_credentials[2]\n",
    "HOST = pg_credentials[3]\n",
    "PORT = pg_credentials[4]\n",
    "\n",
    "connection = pg.connect_to_postgresql(DB_NAME, USER, PASSWORD, HOST, PORT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31d7dab5-9e20-48da-aefc-e6ddf5752c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Table 'WNY_health' created or already exists.\n",
      "âœ… Data inserted into 'WNY_health' successfully.\n"
     ]
    }
   ],
   "source": [
    "loading_wny_health = True\n",
    "if connection and loading_wny_health:\n",
    "    pg_credentials = pg.get_connection_credentials()\n",
    "    pg.create_table_from_dataframe(df_hel, \"WNY_health\", DB_NAME, USER, PASSWORD, HOST, PORT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90983cf5-93a0-499a-ba17-a234838f0691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Table 'chronic_disease' created or already exists.\n"
     ]
    }
   ],
   "source": [
    "loading_chronic_disease = True\n",
    "if connection and loading_chronic_disease:\n",
    "    pg_credentials = pg.get_connection_credentials()\n",
    "    pg.create_table_from_dataframe(df_chronic_disease, \"chronic_disease\", DB_NAME, USER, PASSWORD, HOST, PORT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47646a6-5e9f-4132-8163-a1b30bee279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_chronic_disease = True\n",
    "if connection and loading_chronic_disease:\n",
    "    pg_credentials = pg.get_connection_credentials()\n",
    "    pg.create_table_from_dataframe(df_chronic_disease, \"chronic_disease\", DB_NAME, USER, PASSWORD, HOST, PORT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a24828-a118-446e-8cc1-93970ef98494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf305be5-8ed3-4c26-a298-0ed46b1f88fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "653d9a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read schema data and found statistics on 6 tables\n",
      "The data contains 101 rows and 37 columns of schema data\n",
      "The schema contains 6 tables\n",
      "The schema contains 101 column names\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Table_Name</th>\n",
       "      <th>Column_Name</th>\n",
       "      <th>Column_Number</th>\n",
       "      <th>SQL_Data_Type</th>\n",
       "      <th>Likely_Primary_Key</th>\n",
       "      <th>Likely_Foreign_Key</th>\n",
       "      <th>Likely_Categorical</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>...</th>\n",
       "      <th>Q_3_Upper_Quartile</th>\n",
       "      <th>Q_4_Top_Quartile_Spread</th>\n",
       "      <th>P_10_Percentile</th>\n",
       "      <th>P_90_Percentile</th>\n",
       "      <th>S_Interquartile_Range</th>\n",
       "      <th>S_Range</th>\n",
       "      <th>S_Minimum_Value</th>\n",
       "      <th>S_Maximum_Value</th>\n",
       "      <th>Inferred_Column_Description</th>\n",
       "      <th>Pandas_Data_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Age</td>\n",
       "      <td>1</td>\n",
       "      <td>BIGINT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>768</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>21</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Table Diabetes Column Age of type BIGINT and m...</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>BMI</td>\n",
       "      <td>2</td>\n",
       "      <td>BIGINT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>768</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>...</td>\n",
       "      <td>36.6</td>\n",
       "      <td>30.5</td>\n",
       "      <td>23.6</td>\n",
       "      <td>41.5</td>\n",
       "      <td>9.3</td>\n",
       "      <td>67.1</td>\n",
       "      <td>0</td>\n",
       "      <td>67.1</td>\n",
       "      <td>Table Diabetes Column BMI of type BIGINT and m...</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Table_Name Column_Name  Column_Number SQL_Data_Type  Likely_Primary_Key  \\\n",
       "0   Diabetes         Age              1        BIGINT                   0   \n",
       "1   Diabetes         BMI              2        BIGINT                   0   \n",
       "\n",
       "   Likely_Foreign_Key  Likely_Categorical  count       mean        std  ...  \\\n",
       "0                   0                   0    768  33.240885  11.760232  ...   \n",
       "1                   0                   0    768  31.992578   7.884160  ...   \n",
       "\n",
       "   Q_3_Upper_Quartile  Q_4_Top_Quartile_Spread  P_10_Percentile  \\\n",
       "0                41.0                     40.0             22.0   \n",
       "1                36.6                     30.5             23.6   \n",
       "\n",
       "   P_90_Percentile  S_Interquartile_Range  S_Range  S_Minimum_Value  \\\n",
       "0             51.0                   17.0     60.0               21   \n",
       "1             41.5                    9.3     67.1                0   \n",
       "\n",
       "   S_Maximum_Value                        Inferred_Column_Description  \\\n",
       "0             81.0  Table Diabetes Column Age of type BIGINT and m...   \n",
       "1             67.1  Table Diabetes Column BMI of type BIGINT and m...   \n",
       "\n",
       "   Pandas_Data_Type  \n",
       "0             int64  \n",
       "1             int64  \n",
       "\n",
       "[2 rows x 37 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_file = r\"C:\\Users\\josep\\IDEAL_AI_Data_Exploration\\schema_statistics.xlsx\"\n",
    "df_schema_data = pd.read_excel(schema_file)\n",
    "print(f\"read schema data and found statistics on {df_schema_data.Table_Name.nunique()} tables\")\n",
    "print(f'The data contains {df_schema_data.shape[0]} rows and {df_schema_data.shape[1]} columns of schema data' )\n",
    "print(f\"The schema contains {df_schema_data['Table_Name'].nunique()} tables\")\n",
    "print(f\"The schema contains {df_schema_data['Column_Name'].count()} column names\")    \n",
    "df_schema_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "630949ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Table_Name', 'Column_Name', 'Column_Number', 'SQL_Data_Type',\n",
       "       'Likely_Primary_Key', 'Likely_Foreign_Key', 'Likely_Categorical',\n",
       "       'count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'S_Count',\n",
       "       'S_Missing_Values', 'S_Unique_Values', 'S_Most_Frequent', 'S_Mean',\n",
       "       'S_Standard_Deviation', 'S_Variance', 'S_Coefficient_of_Variation',\n",
       "       'S_Skewness', 'S_Kurtosis', 'Q_1_Lower_Quartile', 'Q_2_Median',\n",
       "       'Q_3_Upper_Quartile', 'Q_4_Top_Quartile_Spread', 'P_10_Percentile',\n",
       "       'P_90_Percentile', 'S_Interquartile_Range', 'S_Range',\n",
       "       'S_Minimum_Value', 'S_Maximum_Value', 'Inferred_Column_Description',\n",
       "       'Pandas_Data_Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_schema_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f3cdff1-9632-4714-b3d0-18f6cd21fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_select_identifiers(table_name):\n",
    "    if table_name == 'Titanic' : \n",
    "        nlp_column = 'passengers'\n",
    "        sql_select_ID = 'PassengerId' \n",
    "    if table_name == 'Penguin' : \n",
    "        nlp_column = 'penguins'\n",
    "        sql_select_ID = 'sample_number' \n",
    "    if table_name == 'Health_Care' : \n",
    "        nlp_column = 'people'\n",
    "        sql_select_ID = 'PatientId' \n",
    "    if table_name == 'Diabetes' : \n",
    "        nlp_column = 'diabetic patients'\n",
    "        sql_select_ID = 'patient_id'  \n",
    "    if table_name == 'Heart' : \n",
    "        nlp_column = 'patients'\n",
    "        sql_select_ID = 'patient_id'    \n",
    "    if table_name == 'HealtheLink' : \n",
    "        nlp_column = 'WNY Patients'\n",
    "        sql_select_ID = 'Research_ID'   \n",
    "    if table_name == 'Chronic_Disease' : \n",
    "        nlp_column = 'prevelence'\n",
    "        sql_select_ID = 'LocationDesc'         \n",
    "    return nlp_column, sql_select_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9227c122-f048-4f77-be55-9eadd8d46b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearStart</th>\n",
       "      <th>YearEnd</th>\n",
       "      <th>LocationAbbr</th>\n",
       "      <th>LocationDesc</th>\n",
       "      <th>DataSource</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Question</th>\n",
       "      <th>Response</th>\n",
       "      <th>DataValueUnit</th>\n",
       "      <th>DataValueType</th>\n",
       "      <th>...</th>\n",
       "      <th>TopicID</th>\n",
       "      <th>QuestionID</th>\n",
       "      <th>ResponseID</th>\n",
       "      <th>DataValueTypeID</th>\n",
       "      <th>StratificationCategoryID1</th>\n",
       "      <th>StratificationID1</th>\n",
       "      <th>StratificationCategoryID2</th>\n",
       "      <th>StratificationID2</th>\n",
       "      <th>StratificationCategoryID3</th>\n",
       "      <th>StratificationID3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>GA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>BRFSS</td>\n",
       "      <td>Disability</td>\n",
       "      <td>Adults with any disability</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>Crude Prevalence</td>\n",
       "      <td>...</td>\n",
       "      <td>DIS</td>\n",
       "      <td>DIS01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CRDPREV</td>\n",
       "      <td>AGE</td>\n",
       "      <td>AGE65P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>GU</td>\n",
       "      <td>Guam</td>\n",
       "      <td>BRFSS</td>\n",
       "      <td>Arthritis</td>\n",
       "      <td>Arthritis among adults</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>Crude Prevalence</td>\n",
       "      <td>...</td>\n",
       "      <td>ART</td>\n",
       "      <td>ART01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CRDPREV</td>\n",
       "      <td>SEX</td>\n",
       "      <td>SEXF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YearStart  YearEnd LocationAbbr LocationDesc DataSource       Topic  \\\n",
       "0       2019     2019           GA      Georgia      BRFSS  Disability   \n",
       "1       2019     2019           GU         Guam      BRFSS   Arthritis   \n",
       "\n",
       "                     Question  Response DataValueUnit     DataValueType  ...  \\\n",
       "0  Adults with any disability       NaN             %  Crude Prevalence  ...   \n",
       "1      Arthritis among adults       NaN             %  Crude Prevalence  ...   \n",
       "\n",
       "   TopicID  QuestionID ResponseID DataValueTypeID  StratificationCategoryID1  \\\n",
       "0      DIS       DIS01        NaN         CRDPREV                        AGE   \n",
       "1      ART       ART01        NaN         CRDPREV                        SEX   \n",
       "\n",
       "   StratificationID1 StratificationCategoryID2 StratificationID2  \\\n",
       "0             AGE65P                       NaN               NaN   \n",
       "1               SEXF                       NaN               NaN   \n",
       "\n",
       "   StratificationCategoryID3  StratificationID3  \n",
       "0                        NaN                NaN  \n",
       "1                        NaN                NaN  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chronic_disease.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4c55604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_select_all(df_schema, table_name):\n",
    "    return f\"SELECT * FROM {table_name};\"\n",
    "\n",
    "def generate_nlp_select_all(df_schema, table_name):\n",
    "    return f\"Show all records from {table_name}.\"\n",
    "\n",
    "def generate_sql_select_all_detail(df_schema, table_name):\n",
    "    table_columns = df_schema[df_schema[\"Table_Name\"] == table_name][\"Column_Name\"]\n",
    "    column_list = \",  \".join([f\"{col}\" for col in table_columns])  # Format column names safely    \n",
    "    return f\"SELECT {column_list} FROM {table_name};\"\n",
    "\n",
    "def generate_nlp_select_all_detail(schema, table_name):\n",
    "    return f\"Show detail for all records from {table_name}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a267d3aa-e055-4dc9-8d43-41d2642907a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table#0 - Name:Diabetes\n",
      "Table#1 - Name:Health_Care\n",
      "Table#2 - Name:Penguin\n",
      "Table#3 - Name:Titanic\n",
      "Table#4 - Name:Heart\n",
      "Table#5 - Name:HealtheLink\n"
     ]
    }
   ],
   "source": [
    "# Initialize the DataFrame for storing training questions\n",
    "df_training_questions = pd.DataFrame(columns=['Table_Name', 'SQL_Type', 'SQL_Query', 'NLP_Query'])\n",
    "\n",
    "# Get unique list of tables from schema data\n",
    "list_of_tables = df_schema_data.Table_Name.unique()\n",
    "\n",
    "for table_number, table_name in enumerate(list_of_tables):\n",
    "    print(f\"Table#{table_number} - Name:{table_name}\")\n",
    "    select_all_sql = generate_sql_select_all(df_schema_data, table_name)\n",
    "    select_all_nlp = generate_nlp_select_all(df_schema_data, table_name)\n",
    "\n",
    "    new_row = pd.DataFrame({\n",
    "        'Table_Name': [table_name], \n",
    "        'SQL_Type': ['select all'], \n",
    "        'SQL_Query': [select_all_sql], \n",
    "        'NLP_Query': [select_all_nlp]\n",
    "    })\n",
    "    df_training_questions = pd.concat([df_training_questions, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71b9fa18-be0e-499a-bbba-ab8291b3ed30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Table_Name</th>\n",
       "      <th>SQL_Type</th>\n",
       "      <th>SQL_Query</th>\n",
       "      <th>NLP_Query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>select all</td>\n",
       "      <td>SELECT * FROM Diabetes;</td>\n",
       "      <td>Show all records from Diabetes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Health_Care</td>\n",
       "      <td>select all</td>\n",
       "      <td>SELECT * FROM Health_Care;</td>\n",
       "      <td>Show all records from Health_Care.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Penguin</td>\n",
       "      <td>select all</td>\n",
       "      <td>SELECT * FROM Penguin;</td>\n",
       "      <td>Show all records from Penguin.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Titanic</td>\n",
       "      <td>select all</td>\n",
       "      <td>SELECT * FROM Titanic;</td>\n",
       "      <td>Show all records from Titanic.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heart</td>\n",
       "      <td>select all</td>\n",
       "      <td>SELECT * FROM Heart;</td>\n",
       "      <td>Show all records from Heart.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HealtheLink</td>\n",
       "      <td>select all</td>\n",
       "      <td>SELECT * FROM HealtheLink;</td>\n",
       "      <td>Show all records from HealtheLink.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Table_Name    SQL_Type                   SQL_Query  \\\n",
       "0     Diabetes  select all     SELECT * FROM Diabetes;   \n",
       "1  Health_Care  select all  SELECT * FROM Health_Care;   \n",
       "2      Penguin  select all      SELECT * FROM Penguin;   \n",
       "3      Titanic  select all      SELECT * FROM Titanic;   \n",
       "4        Heart  select all        SELECT * FROM Heart;   \n",
       "5  HealtheLink  select all  SELECT * FROM HealtheLink;   \n",
       "\n",
       "                            NLP_Query  \n",
       "0     Show all records from Diabetes.  \n",
       "1  Show all records from Health_Care.  \n",
       "2      Show all records from Penguin.  \n",
       "3      Show all records from Titanic.  \n",
       "4        Show all records from Heart.  \n",
       "5  Show all records from HealtheLink.  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training_questions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "822147c7-d74b-49ad-a05c-6e5e5f996681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SQL query for each column in each table based on the most frequent value\n",
    "for index, row in df_schema_data.iterrows():\n",
    "    table_name = row['Table_Name']\n",
    "    column_name = row['Column_Name']\n",
    "    most_frequent_value = row['S_Most_Frequent']\n",
    "    \n",
    "    nlp_column, sql_from_column = get_select_identifiers(table_name)\n",
    "    \n",
    "    if isinstance(most_frequent_value, str):\n",
    "        most_frequent_value = f\"'{most_frequent_value}'\"\n",
    "    \n",
    "    # Generate SQL query\n",
    "    sql_query = f\"SELECT COUNT(diatinct {sql_from_column}) FROM {table_name} WHERE {column_name} = {most_frequent_value};\"\n",
    "    nlp_query = f\"how many {nlp_column} in {table_name} with a {column_name} is {most_frequent_value};\"\n",
    "    \n",
    "    new_row = pd.DataFrame({\n",
    "        'Table_Name': [table_name], \n",
    "        'SQL_Type': ['select count of filter'], \n",
    "        'SQL_Query': [sql_query], \n",
    "        'NLP_Query': [nlp_query]\n",
    "    })\n",
    "    df_training_questions = pd.concat([df_training_questions, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac859663-2c14-46a6-9e7d-ba0d5797784b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Diabetes', 'Health_Care', 'Penguin', 'Titanic', 'Heart',\n",
       "       'HealtheLink'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_schema_data.Table_Name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2f4e94e-2c23-4907-ac6d-9efca862ebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SQL query for each column in each table based on the most frequent value\n",
    "for index, row in df_schema_data.iterrows():\n",
    "    table_name = row['Table_Name']\n",
    "    column_name = row['Column_Name']\n",
    "    likely_categorical = row['Likely_Categorical']\n",
    "    \n",
    "    nlp_column, sql_from_column = get_select_identifiers(table_name)\n",
    "    \n",
    "    if likely_categorical and table_name != 'Penguin': \n",
    "        if table_name == 'titanic':\n",
    "            categories = df_titanic[column_name].unique()\n",
    "        if table_name == 'Heart':\n",
    "            categories = df_heart[column_name].unique()  \n",
    "        if table_name == 'HealtheLink':\n",
    "            categories = df_hel[column_name].unique()  \n",
    "        if table_name == 'Diabetes':\n",
    "            column_name = column_name.lower()\n",
    "            categories = df_diabetes[column_name].unique()    \n",
    "        if table_name == 'Penguin':\n",
    "            categories = df_penguins[column_name].unique()              \n",
    "        \n",
    "        if len(categories) < 50: \n",
    "            for category_value in categories:  \n",
    "    \n",
    "                if isinstance(category_value, str):\n",
    "                    category_value = f\"'{category_value}'\"\n",
    "                \n",
    "\n",
    "                # Generate SQL query\n",
    "                sql_query = f\"SELECT COUNT(distinct {sql_from_column}) FROM {table_name} WHERE {column_name} = {category_value};\"\n",
    "                nlp_query = f\"How many {nlp_column} where {column_name} is {category_value};\"\n",
    "    \n",
    "                new_row = pd.DataFrame({\n",
    "                    'Table_Name': [table_name], \n",
    "                    'SQL_Type': ['select count of category'], \n",
    "                    'SQL_Query': [sql_query], \n",
    "                    'NLP_Query': [nlp_query]   })\n",
    "                df_training_questions = pd.concat([df_training_questions, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a31a010-62d0-4876-993c-750d9ecd6420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "['UNKNOWN' 10 7 5 8 9 'P' 6]\n"
     ]
    }
   ],
   "source": [
    "categories = df_hel.ADI_State.unique() \n",
    "print(len(categories))\n",
    "print(categories) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7674ca9e-ef77-4aa9-ab83-1b93ca9458be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "['N' 'Y']\n"
     ]
    }
   ],
   "source": [
    "categories = df_hel.PreDiabetes.unique() \n",
    "print(len(categories))\n",
    "print(categories) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c58b559-308a-4b94-8ff3-7f71afe460de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[nan 'UnDiagnosed' 'Diagnosed']\n"
     ]
    }
   ],
   "source": [
    "categories = df_hel.PD_Type.unique() \n",
    "print(len(categories))\n",
    "print(categories) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "027b8f4c-d80f-43b8-b442-534c4f73efcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Research_ID', 'Age', 'Sex', 'Race_Level_1', 'Race_Level_2',\n",
       "       'Ethnicity', 'Zip_Code', 'County', 'ADI_State', 'ADI_National', 'Year',\n",
       "       'Asthma', 'Diabetes', 'Diabetes_Poor_Control', 'Diabetes_Type',\n",
       "       'HbA1c_Result', 'Hypertension', 'BP_Control', 'BP_Result', 'Obesity',\n",
       "       'PreDiabetes', 'PD_Type', 'Tobacco', 'Breast_Cancer_Screening',\n",
       "       'Cervical_Cancer_Screening', 'Colorectal_Cancer_Screening'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hel.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de8cae66-7d1b-4f31-a629-26e07e68740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_questions.to_parquet(\"training_questions.parquet\") \n",
    "df_training_questions.to_csv(\"training_questions.csv\") \n",
    "df_training_questions.to_excel(\"training_questions.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21a90859-78f4-4848-bfc0-bdf8a9e3310c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(591, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training_questions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4becfc-8d64-45a9-be30-6a21810b54d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0c54b1-9215-45f8-87c8-6937c73b279c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27cb780-3121-43cb-9efd-27d16e06bb7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f4d437-d8a9-42f4-bce5-477a342bc8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c0219e-3c87-430b-987e-d1889ed44b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d15c15fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storyboard Created : sql_generation \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "report_date_stamp = datetime.now().date()\n",
    "word_file_path = os.path.join(f\"{solution_name}_{report_date_stamp}_storyboard.docx\")\n",
    "data_story_doc.save(word_file_path)    \n",
    "ql.pvlog('info',f\"Storyboard Created : {solution_name} \")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72244be9",
   "metadata": {},
   "source": [
    "## Step 0 - Process End - display log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "134074a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-08 18:59:55,293 - INFO - START sql_generation =============================================\n",
      "2025-04-08 18:59:55,293 - INFO - START sql_generation Start Time = 2025-04-08 18:59:55\n",
      "2025-04-08 18:59:55,307 - INFO - sql_generation Step 0 - Initialize the configuration file parser\n",
      "2025-04-08 18:59:55,307 - INFO - Process started sql_generation on Date:04-08-2025 at Time:06:59:55 PM \n",
      "2025-04-08 18:59:58,279 - INFO - Storyboard Created : sql_generation \n",
      "2025-04-08 18:59:58,287 - INFO - PERFORMANCE sql_generation The total process duration was:2.99\n",
      "2025-04-08 18:59:58,287 - INFO - PERFORMANCE sql_generation Stop Time = 2025-04-08 18:59:58\n",
      "2025-04-08 18:59:58,287 - INFO - PERFORMANCE sql_generation Short process duration less than 3 Seconds:2.99\n",
      "2025-04-08 18:59:58,288 - INFO - PERFORMANCE sql_generation Performance optimization is not reccomended\n",
      "2025-04-08 18:59:58,288 - INFO - END sql_generation =============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate and classify the process performance \n",
    "status = ql.calculate_process_performance(solution_name, start_time) \n",
    "print(ql.append_log_file(solution_name))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf97414",
   "metadata": {},
   "source": [
    "#### https://github.com/JoeEberle/ -- josepheberle@outlook.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbda4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
