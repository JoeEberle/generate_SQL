{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "237aab5c",
   "metadata": {},
   "source": [
    "# SQL Generation \n",
    "\n",
    "#### Generates SQL for table creation, sample queries and ETL Processing \n",
    "\n",
    "The quote from Good Will Hunting (1997) is:\n",
    "\n",
    "***\"My boy's wicked smart.\"*** â€“ Morgan O'Mally (played by Casey Affleck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b660f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_intallation = False \n",
    "if first_intallation: \n",
    "    !pip install --upgrade bottleneck\n",
    "    !pip install pipreqs\n",
    "# pipreqs /path/to/your/project --force    \n",
    "# !pip install numpy==1.24.3\n",
    "# !pip install --upgrade numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deffe246",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'khutilities'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkhutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_manager\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mfm\u001b[39;00m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkhutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquick_logger\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mql\u001b[39;00m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkhutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtalking_code\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtc\u001b[39;00m \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'khutilities'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import schedule\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import khutilities.file_manager as fm \n",
    "import khutilities.quick_logger as ql \n",
    "import khutilities.talking_code as tc \n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "from IPython.display import Video\n",
    "import time\n",
    "import story_board as sb \n",
    "from IPython.display import Markdown, display, Image\n",
    "print(f\"Libraries Imported successfully on {datetime.now().date()} at {datetime.now().time()}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7f1918-fc06-4335-81bc-17557136ddcd",
   "metadata": {},
   "source": [
    "#### Required Setup Step 0 - Intitiate Configuration Settings and name the overall solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1984f04-117f-4dc5-98e9-9c701b3e3a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser \n",
    "config = configparser.ConfigParser()\n",
    "cfg = config.read('config.ini')  \n",
    "solution_name = 'sql_generation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092cdb4f-95e5-4d0b-9435-f60b3f117f8b",
   "metadata": {},
   "source": [
    "#### Required Setup Step 0 - Intitiate Logging and debugging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3697cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging # built in python library that does not need to be installed \n",
    "import khutilities.file_manager as fm \n",
    "import khutilities.quick_logger as ql \n",
    "\n",
    "global start_stime \n",
    "start_time = ql.set_start_time()\n",
    "logging = ql.create_logger_start(solution_name) \n",
    "ql.pvlog('info',f\"Process started {solution_name} on Date:{datetime.now().strftime('%m-%d-%Y')} at Time:{datetime.now().strftime('%I:%M:%S %p')} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8934b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Document\n",
    "report_date_stamp = datetime.now().date()\n",
    "report_time_stamp = datetime.now().time()\n",
    "data_story_doc = Document()\n",
    "data_story_doc.add_heading(f\"Data Science Story Board - {solution_name}\", level=1)\n",
    "data_story_doc.add_heading(f\"Processed on : {report_date_stamp} at {report_time_stamp}\", level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456454de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91b853b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abe3d82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "definition = '''\n",
    "\n",
    "## SQL Generation \n",
    "\n",
    "1. **Create Table**  \n",
    "2. **SQL Select**  \n",
    "3. **ETL Process**  \n",
    "\n",
    "''' \n",
    "# Write the solution definitions out to the solution_description.md file\n",
    "file_name = \"generate_sql.md\"\n",
    "with open(file_name, 'w', encoding='utf-8') as f:\n",
    "    f.write(definition)  # Write the template to the readme.md file\n",
    "\n",
    "# Display the definition as formatted Markdown in the notebook\n",
    "display(Markdown(definition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971b7ca6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "definition = '''\n",
    "\n",
    "\n",
    "\n",
    "''' \n",
    "sb.outmd(definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ba0dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "definition = '''\n",
    "## SQL Generation \n",
    "\n",
    "ðŸ”¹ SQL Generation will generate various forms of SQL based upon the datas descriptive statistics:\n",
    "\n",
    "1. âœ… **Create Table** â†’ Adds a **table_name** for the table or dataset.\n",
    "2. âœ… **SQL Select** â†’ Adds a **column_name** for current column, how pandas named the raw data.\n",
    "3. âœ… **ETL Process** â†’ Adds a column for the **pandas.dtype**, how pandas inferred the raw data.\n",
    "\n",
    "\n",
    "''' \n",
    "sb.outmd(definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f587a0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "getting_schema_data = True\n",
    "if getting_schema_data: \n",
    "    \n",
    "    df = pd.read_excel(\"schema_statistics.xlsx\")    # Read the CSV file into a pandas DataFrame\n",
    "    print(f'The data contains {df.shape[0]} rows and {df.shape[1]} columns of schema data' )\n",
    "    print(f\"The schema contains {df['Table_Name'].nunique()} tables\")\n",
    "    print(f\"The schema contains {df['Column_Name'].count()} column names\")    \n",
    "    df_schema_data = df  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630949ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schema_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c55604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_select_all(df_schema, table_name):\n",
    "    \"\"\" SQL select all detail from table\n",
    "    \"\"\"\n",
    "\n",
    "    table_columns = df_schema[df_schema[\"Table_Name\"] == table_name][\"Column_Name\"] # Filter schema metadata for the specified table\n",
    "    if table_columns.empty:    # Check if the table exists in the schema\n",
    "        return f\"-- No columns found for table: {table_name}\"\n",
    "\n",
    "    column_list = \",  \".join([f\"{col}\" for col in table_columns])  # Format column names safely\n",
    "    sql_query = f\"SELECT  {column_list}\\nFROM {table_name};\"   # Generate the SELECT statement  \n",
    "\n",
    "    return sql_query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808dfbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_count_all(df_schema, table_name):\n",
    "    \"\"\" generate_sql_count_all \"\"\" \n",
    "    return f\"SELECT count(*) FROM {table_name};\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0098d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schema_data[['Table_Name', 'Column_Name', 'Column_Number', 'Pandas_Data_Type','S_Most_Frequent']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06354b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schema_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3912d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_select_all_filter(df_schema, table_name, column_name):\n",
    "    \"\"\" generate_sql_select_all_filter\n",
    "    \"\"\"\n",
    "    # Filter schema metadata for the specified table\n",
    "    table_columns = df_schema[df_schema[\"Table_Name\"] == table_name][\"Column_Name\"]\n",
    "\n",
    "    # Check if the table exists in the schema\n",
    "    if table_columns.empty:\n",
    "        return f\"-- No columns found for table: {table_name}\"\n",
    "\n",
    "    # Generate the SELECT statement\n",
    "    column_list = \",  \".join([f\"{col}\" for col in table_columns])  # Format column names safely\n",
    "    sql_query = f\"SELECT  {column_list}\\nFROM {table_name} \" \n",
    "    sql_query += f\"WHERE {column_name} = \\n\"    \n",
    "\n",
    "    return sql_query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc318d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_select_count_all_filter(df_schema, table_name, column_name, column_value):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    sql_query = f\"SELECT Count(*) \\nFROM {table_name} \" \n",
    "    sql_query += f\"WHERE {column_name} = '{column_value}'\\n\"    \n",
    "\n",
    "    return sql_query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e15dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_nlp_select_all(df_schema, table_name):\n",
    "    \"\"\"\n",
    "    Generates a SQL Server SELECT statement for a given table based on df_schema.\n",
    "\n",
    "    Parameters:\n",
    "    df_schema (pd.DataFrame): The schema metadata DataFrame.\n",
    "    table_name (str): The name of the table for which to generate the SELECT statement.\n",
    "\n",
    "    Returns:\n",
    "    str: The generated natural language question assoicated with the SQL SELECT statement.\n",
    "    \"\"\"\n",
    "    # Generate the NLP question\n",
    "    question_random = random.randint(1, 9)\n",
    "    \n",
    "    if question_random == 1:\n",
    "        nlp_question = f\"Can you show me all the details from the {table_name} table?\"\n",
    "    elif question_random == 2:\n",
    "        nlp_question = f\"What information is stored in the {table_name} table?\"\n",
    "    elif question_random == 3:\n",
    "        nlp_question = f\"Please provide every detail from the {table_name} table.\"\n",
    "    elif question_random == 4:\n",
    "        nlp_question = f\"What do you know about {table_name}?\"   \n",
    "    elif question_random == 5:\n",
    "        nlp_question = f\"Can you list everything in the {table_name} table for me?\"     \n",
    "    elif question_random == 6:\n",
    "        nlp_question = f\"What are all the entries stored in the {table_name} table?\"    \n",
    "    elif question_random == 7:\n",
    "        nlp_question = f\"provide examples of {table_name} ?\"           \n",
    "    elif question_random == 8:\n",
    "        nlp_question = f\"show me examples of {table_name} ?\"  \n",
    "    elif question_random == 9:\n",
    "        nlp_question = f\"I need to see all the content of the {table_name}. Could you show that?\"          \n",
    "\n",
    "    return nlp_question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7179c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "table_name = \"Diabetes\"  # Replace with your desired table name\n",
    "sql_statement = generate_sql_select_all(df_schema_data, table_name)\n",
    "\n",
    "print(sql_statement)   # Print SQL statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ab663",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_schema_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce38eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_select_all(df_schema, table_name):\n",
    "    return f\"SELECT * FROM {table_name};\"\n",
    "\n",
    "def generate_nlp_select_all(df_schema, table_name):\n",
    "    return f\"Show all records from {table_name}.\"\n",
    "\n",
    "def generate_sql_select_all_explicit(df_schema, table_name):\n",
    "    table_columns = df_schema[df_schema[\"Table_Name\"] == table_name][\"Column_Name\"]\n",
    "    column_list = \",  \".join([f\"{col}\" for col in table_columns])  # Format column names safely    \n",
    "    return f\"SELECT {column_list} FROM {table_name};\"\n",
    "\n",
    "def generate_nlp_select_all_explicit(schema, table_name):\n",
    "    return f\"Show detail for all records from {table_name}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135b8bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DataFrame for storing training questions\n",
    "df_training_questions = pd.DataFrame(columns=['Table_Name', 'SQL_Type', 'SQL_Query', 'NLP_Query'])\n",
    "\n",
    "# Get unique list of tables from schema data\n",
    "list_of_tables = df_schema_data.Table_Name.unique()\n",
    "\n",
    "# Generate SQL and NLP queries for each table\n",
    "for table_number, table_name in enumerate(list_of_tables):\n",
    "    print(f\"Table#{table_number} - Name:{table_name}\")\n",
    "    \n",
    "    select_all_sql = generate_sql_select_all(df_schema_data, table_name)\n",
    "    print(f\"Select All SQL: {select_all_sql}\")\n",
    "    \n",
    "    select_all_nlp = generate_nlp_select_all(df_schema_data, table_name)\n",
    "    print(f\"Select All NLP: {select_all_nlp}\")\n",
    " \n",
    "    new_row = pd.DataFrame({\n",
    "        'Table_Name': [table_name], \n",
    "        'SQL_Type': ['select all'], \n",
    "        'SQL_Query': [select_all_sql], \n",
    "        'NLP_Query': [select_all_nlp]\n",
    "    })\n",
    "    df_training_questions = pd.concat([df_training_questions, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df50bbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_questions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3119b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic_columns = df_schema_data[df_schema_data[\"Table_Name\"] == 'Titanic']\n",
    "df_titanic_columns.head(100)                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b315d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schema_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12d547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schema_data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea15406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SQL query for each column in each table based on the most frequent value\n",
    "for index, row in df_schema_data.iterrows():\n",
    "    table_name = row['Table_Name']\n",
    "    column_name = row['Column_Name']\n",
    "    most_frequent_value = row['S_Most_Frequent']\n",
    "    \n",
    "    # Check if the most frequent value is a string and needs to be quoted\n",
    "    if isinstance(most_frequent_value, str):\n",
    "        most_frequent_value = f\"'{most_frequent_value}'\"\n",
    "    \n",
    "    # Generate SQL query\n",
    "    sql_query = f\"SELECT COUNT(*) FROM {table_name} WHERE {column_name} = {most_frequent_value};\"\n",
    "    nlp_query = f\"HOW MANY RECORDS FROM {table_name} with a {column_name} is {most_frequent_value};\"\n",
    "    \n",
    "    new_row = pd.DataFrame({\n",
    "        'Table_Name': [table_name], \n",
    "        'SQL_Type': ['select count of filter'], \n",
    "        'SQL_Query': [sql_query], \n",
    "        'NLP_Query': [nlp_query]\n",
    "    })\n",
    "    df_training_questions = pd.concat([df_training_questions, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42abc670",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_questions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003f8cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_select_from_identifiers(table_name):\n",
    "    if table_name == 'Titanic' : \n",
    "        nlp_column = 'passengers'\n",
    "        sql_select_ID = 'PassengerId' \n",
    "    if table_name == 'penguins' : \n",
    "        nlp_column = 'penguins'\n",
    "        sql_select_ID = 'ResearchId' \n",
    "    if table_name == 'healthcare' : \n",
    "        nlp_column = 'people'\n",
    "        sql_select_ID = 'PatientId' \n",
    "    return nlp_column, sql_select_ID\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec238b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SQL query for each column in each table based on the most frequent value\n",
    "for index, row in df_schema_data.iterrows():\n",
    "    table_name = row['Table_Name']\n",
    "    column_name = row['Column_Name']\n",
    "    likely_categorical = row['Likely_Categorical']\n",
    "    \n",
    "    if table_name == 'Titanic' : \n",
    "        nlp_column = 'passengers'\n",
    "        nlp_from_column = 'PassengerId' \n",
    "    \n",
    "    \n",
    "    if likely_categorical and table_name == 'Titanic' : \n",
    "        categories = df_titanic[column_name].unique()\n",
    "        \n",
    "        if len(categories) < 10: \n",
    "            for category_value in categories:  \n",
    "    \n",
    "                if isinstance(category_value, str):\n",
    "                    category_value = f\"'{category_value}'\"\n",
    "                \n",
    "\n",
    "                # Generate SQL query\n",
    "                sql_query = f\"SELECT COUNT(distinct {nlp_from_column}) FROM {table_name} WHERE {column_name} = {category_value};\"\n",
    "                nlp_query = f\"How many {nlp_column} where {column_name} is {category_value};\"\n",
    "    \n",
    "    new_row = pd.DataFrame({\n",
    "        'Table_Name': [table_name], \n",
    "        'SQL_Type': ['select count of category'], \n",
    "        'SQL_Query': [sql_query], \n",
    "        'NLP_Query': [nlp_query]\n",
    "    })\n",
    "    df_training_questions = pd.concat([df_training_questions, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8424a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_questions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46ae65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_questions.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc09692",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schema_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f93b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_questions.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0905fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b570c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a194496",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fd84c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0850bc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_category_filters(table_name)\n",
    "\n",
    "# Initialize an empty DataFrame to store SQL and NLP queries\n",
    "df_training_questions = pd.DataFrame(columns=['Table_Name', 'SQL_Type', 'SQL_Query', 'NLP_Query'])\n",
    "\n",
    "# Process each row in schema data to generate queries\n",
    "for index, row in df_schema_data.iterrows():\n",
    "    if row['Likely_Categorical'] == True:  # Adjusted for Boolean True\n",
    "        table_name = row['Table_Name']\n",
    "        column_name = row['Column_Name']\n",
    "        num_unique = unique_counts[table_name].get(column_name, 0)\n",
    "\n",
    "        if num_unique <= 10:\n",
    "            # Construct the SQL query\n",
    "            sql_query = f\"SELECT COUNT(*) FROM {table_name} WHERE {column_name} = '{row['S_Most_Frequent']}'\"\n",
    "            nlp_query = f\"How many records from {table_name} where {column_name} = '{row['S_Most_Frequent']}'?\"\n",
    "\n",
    "            # Append to the DataFrame\n",
    "            new_row = pd.DataFrame({\n",
    "                'Table_Name': [table_name], \n",
    "                'SQL_Type': ['select count of filter'], \n",
    "                'SQL_Query': [sql_query], \n",
    "                'NLP_Query': [nlp_query]\n",
    "            })\n",
    "            df_training_questions = pd.concat([df_training_questions, new_row], ignore_index=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df_training_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a42c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4f3783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a19f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample schema data\n",
    "df_schema_data = pd.DataFrame({\n",
    "    'Table_Name': ['table1', 'table1', 'table2', 'table2'],\n",
    "    'Column_Name': ['category1', 'category2', 'category1', 'category2'],\n",
    "    'Likely_Categorical': [True, False, True, True],  # Now using Boolean True/False\n",
    "    'S_Most_Frequent': [10, 'A', 20, 'B']  # Assuming these are the most frequent values for demonstration\n",
    "})\n",
    "\n",
    "# Sample actual data unique counts (simulated here, replace with actual data fetching logic)\n",
    "unique_counts = {\n",
    "    'table1': {'category1': 8, 'category2': 15},\n",
    "    'table2': {'category1': 10, 'category2': 9}\n",
    "}\n",
    "\n",
    "# Initialize an empty DataFrame to store SQL and NLP queries\n",
    "df_training_questions = pd.DataFrame(columns=['Table_Name', 'SQL_Type', 'SQL_Query', 'NLP_Query'])\n",
    "\n",
    "# Process each row in schema data to generate queries\n",
    "for index, row in df_schema_data.iterrows():\n",
    "    if row['Likely_Categorical'] == True:  # Adjusted for Boolean True\n",
    "        table_name = row['Table_Name']\n",
    "        column_name = row['Column_Name']\n",
    "        num_unique = unique_counts[table_name].get(column_name, 0)\n",
    "\n",
    "        if num_unique <= 10:\n",
    "            # Construct the SQL query\n",
    "            sql_query = f\"SELECT COUNT(*) FROM {table_name} WHERE {column_name} = '{row['S_Most_Frequent']}'\"\n",
    "            nlp_query = f\"How many records from {table_name} where {column_name} = '{row['S_Most_Frequent']}'?\"\n",
    "\n",
    "            # Append to the DataFrame\n",
    "            new_row = pd.DataFrame({\n",
    "                'Table_Name': [table_name], \n",
    "                'SQL_Type': ['select count of filter'], \n",
    "                'SQL_Query': [sql_query], \n",
    "                'NLP_Query': [nlp_query]\n",
    "            })\n",
    "            df_training_questions = pd.concat([df_training_questions, new_row], ignore_index=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df_training_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d1bf89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1d68ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a261d35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cf6000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3b9f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d99e8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_questions = pd.dataframe([['Table_Name','SQL_Type','SQL_Query','NLP_Query']])\n",
    "list_of_tables = df_schema_data.Table_Name.unique()\n",
    "for table_number, table_name in enumerate(list_of_tables):\n",
    "    print(f\"Table#{table_number} - Name:{table_name}  \")\n",
    "    select_all = generate_sql_select_all(df_schema_data, table_name)\n",
    "    print(f\"Select All SQL : {select_all} \\n\")\n",
    "    select_all_nlp = generate_nlp_select_all(df_schema_data, table_name)\n",
    "    df_training_questions.loc = table_name, \"select all\", select_all, select_all_nlp\n",
    "    print(f\"Select All NLP : {select_all_nlp} \\n \")  \n",
    "    \n",
    "    \n",
    "    select_count_all = generate_sql_count_all(df_schema_data, table_name)  \n",
    "    print(f\"Select Count All : {select_count_all} \\n \")\n",
    "    select_all = generate_sql_count_all(df_schema_data, table_name)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653d9a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schema_data = pd.read_excel(\"schema_statistics.xlsx\")\n",
    "print(f\"read schema data and found statistics on {df_schema_data.Table_Name.nunique()} tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11b4345",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = df_schema_data.Table_Name.unique()\n",
    "df_schema_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d24713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a168b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ea1808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4735319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd17c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f9e781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401a99b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c0d461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd27b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcfe49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef91524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f17c55a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ad7f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6542a35c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eed9911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15c15fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "report_date_stamp = datetime.now().date()\n",
    "word_file_path = os.path.join(f\"{solution_name}_{report_date_stamp}_storyboard.docx\")\n",
    "data_story_doc.save(word_file_path)    \n",
    "ql.pvlog('info',f\"Storyboard Created : {solution_name} \")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72244be9",
   "metadata": {},
   "source": [
    "## Step 0 - Process End - display log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134074a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and classify the process performance \n",
    "status = ql.calculate_process_performance(solution_name, start_time) \n",
    "print(ql.append_log_file(solution_name))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf97414",
   "metadata": {},
   "source": [
    "#### https://github.com/JoeEberle/ -- josepheberle@outlook.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
